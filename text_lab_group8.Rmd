---
title: "text_lab"
author: "Courtney Kennedy, Josephine Johannes, Maggie Tran"
date: "9/30/2020"
output: html_document
---
## The Process
Steps: 
1. Find newspapers that correspond to a specific region in the United States and download multiple articles as one text file 
2. Load the files and essential libraries 
3. Find the frequency of words per region by tokenizing the document 
4. Use Lexicons that help classify the sentiment of the respective words 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r include=FALSE}
library(tidyverse)
#install.packages("tidytext")
library(tidytext)
#install.packages("ggwordcloud")
library(ggwordcloud)
#install.packages("gutenbergr") 
library(gutenbergr)
#install.packages('textdata')
library(textdata)
library(ggpubr)
#setwd("C:/Users/student/Documents/Fall21/introDS/text-lab")
```

```{r include=FALSE}
# Sentiments 
get_sentiments('afinn')# we see a list of words and there classification, 2,467 - not really that many overall. 

get_sentiments('nrc')# looks like a good amount more 13,891, but as we can see words are classified in several different categories. 

get_sentiments('bing')# looks like a good amount more 6,776, but as we can see just negative and positive. 
```

## West Coast {.tabset}

### Word Frequency 

1. The first step in the process is finding the frequency of words per region.

```{r}
#Load in west coast file
cali_inag <- read_lines("cali-news.txt")

#Create tibble data structure
cali_inag <- tibble(cali_inag)

#Convert to character data type
cali_inag$cali_inag <- as.character(cali_inag$cali_inag)

#Determine Word Frequency in west coast
cali_inag <- cali_inag %>%
  unnest_tokens(word, cali_inag)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)

#Top word frequencies
head(cali_inag, 10)
```

### Sentiment Analysis

2. Using the word frequency from step 1, we use lexicons that help to classify the words in the documents using sentiment. 
```{r}
# Inner join with sentiments 
cali_sentiment_affin <- cali_inag %>%
  inner_join(get_sentiments("afinn"))

cali_sentiment_nrc <- cali_inag %>%
  inner_join(get_sentiments("nrc"))

cali_sentiment_bing <- cali_inag %>%
  inner_join(get_sentiments("bing"))

```

```{r}
# Count of word sentiments in West Coast region
table(cali_sentiment_bing$sentiment)
table(cali_sentiment_nrc$sentiment)
```

```{r}
# Distribution of positive and negative word sentiments 
west_sent_plot <- ggplot(data = cali_sentiment_affin, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("West Coast Sentiment Range")+
  theme_minimal()

west_sent_plot
```

The sentiment analysis using bing shows that the west coast uses more negative words than positive words.  The nrc sentitiment contradicts this and has a higher positive sentiment word count that negative, but also adds to this by showing that most of the words invoke a feeling of trust and then the second highest feeling is fear. The affin sentiment distribution shows that there is a slight favor of negative sentiment words in the west coast region's newspapers.  Overall it appears that the negative sentiment is more common, and it most likely correlates to the more "doomsday" approach that more liberal regions have, such as the west coast, since the approach is instilling fear to promote change in current behaviors.  There is also a use of trust especially towards new technology and this is where the trust and positive sentiment most likely comes in.   

### Word Cloud 

3. Create a word cloud to see the popularity of the words

```{r}
set.seed(42)
west_cloud <- ggplot(cali_inag[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  theme_minimal() +
  ggtitle("West Coast Word Cloud")

west_cloud
```

We see that the most common words from the west coast region are some expected terms: climate, change, los, angeles, and then some other words that indicate the west coast's main concerns with climate change: heat, water, temperatures, warming, extreme, drought, and fire.  Overall these more specific words correlate with the climate change symptoms that the west coast is experiencing such as water shortages, extreme temperatures, and wildfires.  Some other popular words seem to correlate with the environmental science industry that is fighting climate change such as electric, industry, environmental, power, companies, and emissions, which all make sense given that the west coast is a hub of environmental research and clean industries. 

## Midwest Region{.tabset}

### Word Frequency

1. The first step in the process is finding the frequency of words per region.

```{r}
#Load in midwest file
midwest_inag <- read_lines("midwest.txt")

#Create tibble data structure
midwest_inag <- tibble(midwest_inag)

#Convert to character data type
midwest_inag$midwest_inag <- as.character(midwest_inag$midwest_inag)

#Determine Word Frequency in west coast
midwest_inag <- midwest_inag %>%
  unnest_tokens(word, midwest_inag)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)

#Top word frequencies
head(midwest_inag, 10)
```

### Sentiment Analysis

2. Using the word frequency from step 1, we use lexicons that help to classify the words in the documents using sentiment. 

```{r}
# Inner join with sentiments

midwest_sentiment_affin <- midwest_inag %>%
  inner_join(get_sentiments("afinn"))

midwest_sentiment_nrc <- midwest_inag %>%
  inner_join(get_sentiments("nrc"))

midwest_sentiment_bing <- midwest_inag %>%
  inner_join(get_sentiments("bing"))
```


```{R}
# Count of word sentiments in midwest region
table(midwest_sentiment_bing$sentiment)
table(midwest_sentiment_nrc$sentiment)
```

```{R}
# Distribution of positive and negative word sentiments 
midwest_sent_plot <- ggplot(data = midwest_sentiment_affin, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("Midwest Sentiment Range")+
  theme_minimal()

midwest_sent_plot
```

The sentiment analysis using bing shows that the midwest uses more negative words than positive words.  The nrc sentiment contradicts this and has a higher positive sentiment word count that negative, but also adds to this by showing that most of the words invoke a feeling of trust. The affin sentiment distribution shows that there is a slight favor of negative sentiment words in the midwests region's newspapers, but the distribution is more even than the west coast distribution.  Overall it appears that the negative and positive sentiment are about even in the midwest, indicating that there is not a strong lean in either positive or negative words.  Overall it seems that the midwest is trying to instill a feeling of trust through talking about climate change.

### Word Cloud

3. Create a word cloud to see the popularity of the words

```{R}
set.seed(42)
midwest_cloud <- ggplot(midwest_inag[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  theme_minimal() +
  ggtitle("Midwest Word Cloud")

midwest_cloud
```

We see that the most common words from the midwest region are some expected terms: climate, change, chicago, and then some other words that indicate the midwest's main concerns with climate change: lake, water, warming, and energy.  Overall these more specific words correlate with the climate change symptoms that the midwest is experiencing such as concerns with the great lakes and the warming of the midwest.  Again overall the words seemed pretty neutral and did not sway in either a positive or negative direction, indicating that the midwest doesn't appear to have very strong opinions on climate change. 

## Mid Atlantic Region  {.tabset}

### Word Frequency

#### Load in Mid Atlantic Region File
```{r} 
# import data from compiled newspaper reading
mid_atl <- read_lines("MidAtlanticRegion.txt")
# make mid_atl into a tibble data structure
mid_atl <- tibble(mid_atl)
```

#### Word Frequencies
1. The first step in the process is finding the frequency of words per region. 
```{r}
#change the data frame variables in mid_atl$mid_atl character types
mid_atl$mid_atl <- as.character(mid_atl$mid_atl)

mid_atl <- mid_atl %>% 
  unnest_tokens(word, mid_atl) %>%
  anti_join(stop_words) %>% count(word, sort=TRUE)
# Top word Frequencies
head(mid_atl, 10)
```

### Sentiment Analysis 
2. Using the word frequency from step 1, we use lexicons that help to classify the words in the documents using sentiment. 
```{r}
mid_atl_sentiment_affin <- mid_atl %>% inner_join(get_sentiments('afinn'))
mid_atl_sentiment_nrc <- mid_atl %>% inner_join(get_sentiments('nrc'))
mid_atl_sentiment_bing <- mid_atl %>% inner_join(get_sentiments('bing'))

table(mid_atl_sentiment_bing$sentiment)

table(mid_atl_sentiment_nrc$sentiment)

```

#### Plot Sentiment 
```{r}
mid_atl_sent_plot <- ggplot(data = mid_atl_sentiment_affin, aes(x=value))+geom_histogram()+ggtitle("Mid Atlantic Region Sentiment Range")+theme_minimal() 

mid_atl_sent_plot
```


From the graph, it seems that there are more words that have a negative sentiment, compared to the amount of words with a positive sentiment. This could be related to how Pennsylvania had recently been hit by Hurricane Ida and is still in the process of recovering from the natural disaster. Governor Tim Wolf also announced the Pennsylvania Climate Action Plan 2021 which may have increased the amount of articles released recently. 

### Word Cloud

Here we use the ggplot package 
```{r}
set.seed(42)
mid_atl_cloud <- ggplot(mid_atl[1:100,], aes(label = word, size = n))+geom_text_wordcloud()+theme_minimal()+ ggtitle("Mid Atlantic Word Cloud")

mid_atl_cloud

```

#### Results: 

There are frequent words in the documents that include science, emissions, global, energy, warming, natural, and university, excluding the words climate and change. I think it would be a good idea to look at different universities and see the overall support for climate change there as well as bigger urban areas. I would say that Pittsburgh is a big urban area that uses a lot of energy so there could be negative sentiment due to the energy consumption in the city. It seems like there has been a correlation with the science as evidence for climate change, so a more negative sentiment could also be seen in scholarly literature. 


## NorthEast Region {.tabset}

### Word Frequency

#### Load in NorthEast Region File
```{r} 
# import data from compiled newspaper reading
north <- read_lines("NorthEastRegion.txt")
# make mid_atl into a tibble data structure
north <- tibble(north)
```

#### Word Frequencies
1. The first step in the process is finding the frequency of words per region. 
```{r}
#change the data frame variables in mid_atl$mid_atl character types
north$north <- as.character(north$north)

north <- north %>% 
  unnest_tokens(word, north) %>%
  anti_join(stop_words) %>% count(word, sort=TRUE)
#top word frequencies
head(north, 10)
```

### Sentiment Analysis 
2. Using the word frequency from step 1, we use lexicons that help to classify the words in the documents using sentiment. 
```{r}
north_sentiment_affin <- north %>% inner_join(get_sentiments('afinn'))
north_sentiment_nrc <- north %>% inner_join(get_sentiments('nrc'))
north_sentiment_bing <- north %>% inner_join(get_sentiments('bing'))

```

#### Plot Sentiment 
```{r}
north_sent_plot <- ggplot(data = north_sentiment_affin, aes(x=value))+geom_histogram()+ggtitle("Northeast Region Sentiment Range")+theme_minimal()

north_sent_plot
```


From the graph, it seems like there are more words that have a negative sentiment compared to those with a positive sentiment. 

### Word Cloud 
Here we use the ggplot package 
```{r}
set.seed(42)
north_cloud <- ggplot(north[1:100,], aes(label = word, size = n))+geom_text_wordcloud()+theme_minimal()+ ggtitle("Northeast Region Word Cloud")

north_cloud

```


#### Results 
Excluding the words "climate", "change", and "maine", it seems like the most frequent words that come up are carbon, warming, bangor, maple, and energy. I think it would be interesting to look at the carbon industry in Maine and see how the environment has been impacted through that industry. If there are carbon plants, this could lead to negative sentiment for climate change because it would decrease profitability for the plants. It's also interesting how maple showed up in the climate change articles because I don't think maple is related to climate change.

<<<<<<< HEAD
## Southwest Region {.tabset}

### Word Frequency

#### Load in Southwest Region File
```{r}
texas_monthly <- read_lines("TexasMonthly.txt")
texas_monthly <- tibble(texas_monthly)
```

#### Word Frequencies
1. The first step in the process is finding the frequency of words per region. 
```{r}
texas_monthly$texas_monthly <- as.character(texas_monthly$texas_monthly)
texas_monthly <- texas_monthly %>%
  unnest_tokens(word, texas_monthly)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)
head(texas_monthly, 10)
```

### Sentiment Analysis 
2. Using the word frequency from step 1, we use lexicons that help to classify the words in the documents using sentiment. 
```{r}
texas_sentiment_affin <- texas_monthly %>%
  inner_join(get_sentiments("afinn"))
texas_sentiment_nrc <- texas_monthly %>%
  inner_join(get_sentiments("nrc"))
texas_sentiment_bing <- texas_monthly %>%
  inner_join(get_sentiments("bing"))
```

#### Plot Sentiment
```{r}
southwest_sent_plot <- ggplot(data = texas_sentiment_affin, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("Southwest Sentiment Range")+
  theme_minimal()

southwest_sent_plot
```

Analysis:

### Word Cloud 
Here we use the ggplot package
```{r}
set.seed(42)
southwest_cloud <- ggplot(texas_monthly[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  theme_minimal()

southwest_cloud
```

#### Results


## Southeast Region {.tabset}

### Word Frequency

#### Load in Southeast Region File
```{r}
atlanta_journal <- read_lines("TheAtlantaJournal.txt")
atlanta_journal <- tibble(atlanta_journal)
```

#### Word Frequencies
1. The first step in the process is finding the frequency of words per region.
```{r}
atlanta_journal$atlanta_journal <- as.character(atlanta_journal$atlanta_journal)
atlanta_journal <- atlanta_journal %>%
  unnest_tokens(word, atlanta_journal)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)
head(atlanta_journal,10)
```

### Sentiment Analysis 
2. Using the word frequency from step 1, we use lexicons that help to classify the words in the documents using sentiment.
```{r}
atlanta_sentiment_affin <- atlanta_journal %>%
  inner_join(get_sentiments("afinn")) #using a inner join to match words and add the sentiment variable
atlanta_sentiment_nrc <- atlanta_journal %>%
  inner_join(get_sentiments("nrc"))
atlanta_sentiment_bing <- atlanta_journal %>%
  inner_join(get_sentiments("bing"))
```

#### Plot Sentiment
```{r}
southeast_sent_plot <- ggplot(data = atlanta_sentiment_affin, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("Southeast Sentiment Range")+
  theme_minimal()

southeast_sent_plot
```

Analysis:

### Word Cloud 
Here we use the ggplot package
```{r}
set.seed(42)
southeast_cloud <- ggplot(atlanta_journal[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  ggtitle("Southeast Word Cloud")
  theme_minimal()

southeast_cloud  
```

#### Results


## Every Region 
=======
## National Comparison 
>>>>>>> 6e137ca7df22c7a0a6f83d9cc25ff4eb3af5952c

```{r}
cali_inag_raw <- as.tibble(read_lines("cali-news.txt"))
midwest_inag_raw <- as.tibble(read_lines("midwest.txt"))
mid_atl_inag_raw <- as.tibble(read_lines("MidAtlanticRegion.txt"))
north_inag_raw <- as.tibble(read_lines("NorthEastRegion.txt"))
southwest_inag_raw <- as.tibble(read_lines("TexasMonthly.txt"))
southeast_inag_raw <- as.tibble(read_lines("TheAtlantaJournal.txt"))

data_prep <- function(x,y,z){
  i <- as_tibble(t(x))
  ii <- unite(i,"text",y:z,remove = TRUE,sep = "")
}


cali_inag_bag <- data_prep(cali_inag_raw,'V1','V2993')
midwest_inag_bag <- data_prep(midwest_inag_raw,'V1','V2376')
mid_atl_inag_bag <- data_prep(mid_atl_inag_raw,'V1','V2238')
north_inag_bag <- data_prep(north_inag_raw, 'V1', 'V2129')
southwest_inag_bag <- data_prep(southwest_inag_raw,'V1','V1405')
southeast_inag_bag <- data_prep(southeast_inag_raw, 'V1','V780')

<<<<<<< HEAD
region <- c("West","Midwest", "Mid-Atlantic", "Northeast", "Southwest", "Southeast")
=======
region <- c("WestCoast","Midwest", "Mid-Atlantic", "Northeast")
>>>>>>> 6e137ca7df22c7a0a6f83d9cc25ff4eb3af5952c


tf_idf_text <- tibble(region,text=t(tibble(cali_inag_bag,midwest_inag_bag, mid_atl_inag_bag, north_inag_bag, southwest_inag_bag, southeast_inag_bag,.name_repair = "universal")))


word_count <- tf_idf_text %>%
  unnest_tokens(word, text) %>%
  count(region, word, sort = TRUE)


total_words <- word_count %>% 
  group_by(region) %>% 
  summarize(total = sum(n))

inag_words <- left_join(word_count, total_words)

inag_words <- inag_words %>%
  bind_tf_idf(word, region, n)

head(inag_words, 100)
View(inag_words)
```

## Compare Word Clouds

```{r}
ggarrange(west_cloud, midwest_cloud, mid_atl_cloud, north_cloud, southwest_cloud, southeast_cloud)
```

## Compare Sentiment Distribution
```{r}
ggarrange(west_sent_plot, midwest_sent_plot, mid_atl_sent_plot, north_sent_plot, southwest_sent_plot, southeast_sent_plot)
```

Results: 
Overall, it seems that the regions chosen had more of a negative sentiment than a positive sentiment for climate change. 

Recommendations: 
I would recommend looking at different universities and trying to get a sense of what the political climate is there. It seems that there’s more support for climate change in more urban areas as opposed to rural areas 

